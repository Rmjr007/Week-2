# -*- coding: utf-8 -*-
"""model_training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eJc6RYRihAkcWh299hgr6VNSpzSpN4T8
"""

# ---------------------------------------------------------------
# ğŸ§  Week-2: Model Training, Comparison, and Best Model Saving
# ---------------------------------------------------------------

import pandas as pd
import numpy as np
import joblib
import os
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# ---------------------------------------------------------------
# ğŸ“˜ Step 1 â€” Load dataset
# ---------------------------------------------------------------
df = pd.read_csv("ev_adoption_dataset_clean.csv")
print("âœ… Dataset loaded successfully! Shape:", df.shape)

# Choose target and feature columns
target = "ev_vehicles_registered"   # ğŸ”¹ Change if your target column differs (e.g., "Cost")
# Exclude 'country' and 'year' from features as they are non-numeric
features = [col for col in df.columns if col not in [target, "year", "country"]]

X = df[features]
y = df[target]

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ---------------------------------------------------------------
# ğŸ“˜ Step 2 â€” Train both models
# ---------------------------------------------------------------
print("\nğŸš€ Training models...")

# Linear Regression
lr = LinearRegression()
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)

# Random Forest Regressor
rf = RandomForestRegressor(n_estimators=200, random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

# ---------------------------------------------------------------
# ğŸ“˜ Step 3 â€” Evaluate both models
# ---------------------------------------------------------------
def evaluate_model(name, y_true, y_pred):
    r2 = r2_score(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    return {
        "Model": name,
        "RÂ² Score": round(r2, 3),
        "MAE": round(mae, 2),
        "RMSE": round(rmse, 2)
    }

results = pd.DataFrame([
    evaluate_model("Linear Regression", y_test, y_pred_lr),
    evaluate_model("Random Forest", y_test, y_pred_rf)
])

print("\nâœ… Model Comparison Summary:\n")
print(results)

# ---------------------------------------------------------------
# ğŸ“˜ Step 4 â€” Visualize model comparison
# ---------------------------------------------------------------
plt.figure(figsize=(8, 5))
plt.bar(results["Model"], results["RÂ² Score"], color=["skyblue", "orange"])
plt.title("Model Performance Comparison (Higher RÂ² is Better)")
plt.ylabel("RÂ² Score")
plt.grid(axis="y", linestyle="--", alpha=0.7)
plt.savefig("model_comparison_plot.png", bbox_inches="tight")
plt.show()

# ---------------------------------------------------------------
# ğŸ“˜ Step 5 â€” Save the best model
# ---------------------------------------------------------------
best_model_row = results.loc[results["RÂ² Score"].idxmax()]
best_model_name = best_model_row["Model"]

if best_model_name == "Random Forest":
    best_model = rf
else:
    best_model = lr

# Create models directory
os.makedirs("models", exist_ok=True)

# Save model and its metrics
joblib.dump(best_model, "models/ev_policy_best_model.pkl")

# Save evaluation summary for reference
results.to_csv("models/model_comparison_summary.csv", index=False)

print(f"\nğŸ† Best model: {best_model_name}")
print("ğŸ“Š Model comparison saved as: models/model_comparison_summary.csv")
print("ğŸ’¾ Best model saved as: models/ev_policy_best_model.pkl")

print("\nğŸ¯ Week-2 task completed successfully!")